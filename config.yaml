# config.yaml

scheduler:
  name: scheduler  # Dask scheduler name.
  image:
    repository: "daskdev/dask"
    tag: 2024.2.1
    pullPolicy: IfNotPresent
    pullSecrets:  # Container image [pull secrets](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/).
    #  - name: regcred
  # Number of schedulers should be <=1 in this deployment.
  replicas: 1
  resources:
    # presume half an m5.xlarge or similar (4vCPU,16GiB RAM)
    limits:
        cpu: 2
        memory: 8G
    requests:
        cpu: 2000m
        memory: 8G
  serviceType: "LoadBalancer"
  env:
    - name: OMP_NUM_THREADS
      value: "1"
    - name: MKL_NUM_THREADS
      value: "1"
    - name: OPENBLAS_NUM_THREADS
      value: "1"
    - name: BLOSC_NOLOCK
      value: "1"
    #- name: EXTRA_APT_PACKAGES
    #  value: build-essential swig libgfortran4 gcc python3-dev
    - name: EXTRA_CONDA_PACKAGES
      value: fsspec==2024.2.0 s3fs==2024.2.0
    - name: EXTRA_PIP_PACKAGES
      value: graphviper==0.0.6 astroviper==0.0.9
  servicePort: 8786
  tolerations: []
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: "kops.k8s.io/instancegroup"
              operator: NotIn
              values: ["workers"]
  nodeSelector: {}  # Node Selector.
  # serviceAccountName: ""

webUI:
  name: webui  # Dask webui name.
  servicePort: 80 # webui service internal port.
  ingress:
    enabled: false  # Enable ingress.
    tls: false  # Ingress should use TLS.
    # secretName: dask-scheduler-tls
    hostname: dask-ui.example.com  # Ingress hostname.
    annotations:  # Ingress annotations. See `values.yaml` for example values.
      # kubernetes.io/ingress.class: "nginx"
      # secretName: my-tls-cert
      # kubernetes.io/tls-acme: "true"

worker:
  image: # duplicate current scheduler default
    repository: "daskdev/dask"
    tag: 2024.2.1
    pullPolicy: IfNotPresent
    pullSecrets:  # Container image [pull secrets](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/).
  replicas: 2
  resources:
    # assuming 8GB RAM per vCPU is enough to fit our largest image plane
    limits:
        cpu: 2
        memory: 16G
    requests:
        cpu: 2000m
        memory: 16G
  #mounts: {}
    #volumes:
    #- name: data
    #  emptyDir: {}
    #volumeMounts:
    #- name: data
    #  mountPath: /data
  env:
    - name: OMP_NUM_THREADS
      value: "1"
    - name: MKL_NUM_THREADS
      value: "1"
    - name: OPENBLAS_NUM_THREADS
      value: "1"
    - name: BLOSC_NOLOCK
      value: "1"
    #- name: EXTRA_APT_PACKAGES
    #  value: build-essential swig libgfortran4 gcc python3-dev
    - name: EXTRA_CONDA_PACKAGES
      value: fsspec==2024.2.0 s3fs==2024.2.0
    - name: EXTRA_PIP_PACKAGES
      value: graphviper==0.0.6 astroviper==0.0.9

jupyter:
  enabled: true
  image:
    repository: "daskdev/dask-notebook"
    tag: 2024.2.1
    #repository: amcnicho/dask-docker-test
    #tag: dask-notebook
    pullPolicy: Always
  replicas: 1
  resources:
    # presume ~quarter of an m5.xlarge or similar (4vCPU,16GiB RAM)
    limits:
        cpu: 1
        memory: 4G
    requests:
        cpu: 1000m
        memory: 4G
  env:
    - name: OMP_NUM_THREADS
      value: "1"
    - name: MKL_NUM_THREADS
      value: "1"
    - name: OPENBLAS_NUM_THREADS
      value: "1"
    - name: BLOSC_NOLOCK
      value: "1"
    #- name: EXTRA_APT_PACKAGES
    #  value: build-essential swig libgfortran4 gcc python3-dev
    - name: EXTRA_CONDA_PACKAGES
      value: fsspec==2024.2.0 s3fs==2024.2.0
    - name: EXTRA_PIP_PACKAGES
      value: graphviper==0.0.6 astroviper==0.0.9
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: "kops.k8s.io/instancegroup"
              operator: NotIn
              values: ["workers"]
